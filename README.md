# Load_LLMs_on_cpu
GGUF LLM models are a type of large language models that use a novel file format called GGUF, which stands for Generalized Graph U-Net Fusion. GGUF is a format that allows efficient inference of quantized models from a single file, making the deployment process simpler and more cost-effective. ¹²

GGUF LLM models can be used in CPU machines for various natural language processing tasks, such as text generation, question answering, summarization, and more. However, using GGUF LLM models on CPU machines may have some limitations, such as lower speed, higher memory consumption, and reduced accuracy compared to GPU machines. 

Colab Notebook Link:- https://colab.research.google.com/drive/1JmFWD5O_-6WWll3-I0Ie4zDewJfDSdWL?usp=sharing
